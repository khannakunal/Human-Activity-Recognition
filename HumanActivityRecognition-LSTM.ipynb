{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\".\\\\Case Studies\\\\Human Activity Recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_names = ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', \n",
    "                 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_data(type_data = 'train'):\n",
    "    \n",
    "    x_data = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        file_name = f'.\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\{type_data}\\\\Inertial Signals\\\\{feature}_{type_data}.txt'\n",
    "        data = pd.read_csv(file_name, delim_whitespace = True, header = None).as_matrix()\n",
    "        x_data.append(data)\n",
    "    \n",
    "    return np.transpose(x_data, (1, 2, 0))\n",
    "\n",
    "def get_y_data(type_data = 'train'):\n",
    "    \n",
    "    y_data = []\n",
    "    \n",
    "    file_name = f'.\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\{type_data}\\\\y_{type_data}.txt'\n",
    "    return pd.get_dummies(pd.read_csv(file_name, delim_whitespace = True, header = None)[0]).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "x_train = get_x_data('train')\n",
    "x_test = get_x_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "y_train = get_y_data('train')\n",
    "y_test = get_y_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = len(x_train[0])\n",
    "feature_count = len(x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "column_list = ['Dropout', 'Multiple LSTM Layers', 'Accuracy']\n",
    "results = pd.DataFrame(columns = column_list)\n",
    "\n",
    "def print_results(model, x_test, y_test, dropout, multiple_layers):\n",
    "    global results\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_modified = [prediction.argmax() for prediction in y_pred]\n",
    "    y_test_modified = [actual_value.argmax() for actual_value in y_test]\n",
    "\n",
    "    print('---------------------------------------------------------------------------------------------')\n",
    "    print('Results for model with dropout: {}, multiple_layers: {}'.format(dropout, multiple_layers))\n",
    "    print(confusion_matrix(y_test_modified, y_pred_modified))\n",
    "    result = model.evaluate(x_test, y_test)\n",
    "    print('Accuracy: {}'.format(result[1]))\n",
    "    print('---------------------------------------------------------------------------------------------')\n",
    "    result = {'Dropout': dropout, 'Multiple LSTM Layers': multiple_layers, 'Accuracy': result[1]}\n",
    "    results = results.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers import LSTM\n",
    "\n",
    "lstm_count_single = 32\n",
    "lstm_count_multiple = 15\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "def fit_model(dropout, multiple_layers, x_train, y_train, x_test, y_test):\n",
    "    print('Running for dropout: {}, layers: {}'.format(dropout, multiple_layers))\n",
    "    if multiple_layers:\n",
    "        lstm_count = lstm_count_multiple\n",
    "    else:\n",
    "        lstm_count = lstm_count_single\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_count, return_sequences=True, input_shape = (vector_size, feature_count)))\n",
    "    model.add(Dropout(dropout))\n",
    "    if multiple_layers:\n",
    "        model.add(LSTM(lstm_count, return_sequences=True))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_test, y_test), epochs=epochs)\n",
    "    print_results(model, x_test, y_test, dropout, multiple_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for dropout: 0.25, layers: False\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.5625 - acc: 0.7758 - val_loss: 0.4389 - val_acc: 0.8660\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1681 - acc: 0.9319 - val_loss: 0.3786 - val_acc: 0.8992\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1443 - acc: 0.9402 - val_loss: 0.3687 - val_acc: 0.8979\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1260 - acc: 0.9497 - val_loss: 0.3034 - val_acc: 0.9131\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1294 - acc: 0.9468 - val_loss: 0.3724 - val_acc: 0.8962\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1191 - acc: 0.9506 - val_loss: 0.3544 - val_acc: 0.8992\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1166 - acc: 0.9502 - val_loss: 0.3186 - val_acc: 0.8972\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1210 - acc: 0.9491 - val_loss: 0.3315 - val_acc: 0.9125\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1178 - acc: 0.9531 - val_loss: 0.3288 - val_acc: 0.9080\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1240 - acc: 0.9460 - val_loss: 0.2992 - val_acc: 0.9060\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1156 - acc: 0.9501 - val_loss: 0.3420 - val_acc: 0.9118\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1196 - acc: 0.9482 - val_loss: 0.3590 - val_acc: 0.9067\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1108 - acc: 0.9505 - val_loss: 0.3576 - val_acc: 0.9080\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1110 - acc: 0.9524 - val_loss: 0.3712 - val_acc: 0.9043\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1268 - acc: 0.9484 - val_loss: 0.4051 - val_acc: 0.9053\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1139 - acc: 0.9505 - val_loss: 0.3317 - val_acc: 0.9091\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1073 - acc: 0.9525 - val_loss: 0.3483 - val_acc: 0.9033\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1065 - acc: 0.9531 - val_loss: 0.3952 - val_acc: 0.9087\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1072 - acc: 0.9512 - val_loss: 0.3377 - val_acc: 0.9080\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1061 - acc: 0.9509 - val_loss: 0.3777 - val_acc: 0.9050\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1141 - acc: 0.9501 - val_loss: 0.4354 - val_acc: 0.9023\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1124 - acc: 0.9497 - val_loss: 0.3759 - val_acc: 0.9141\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.1036 - acc: 0.9551 - val_loss: 0.3534 - val_acc: 0.9087\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1040 - acc: 0.9543 - val_loss: 0.3875 - val_acc: 0.9077\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1027 - acc: 0.9544 - val_loss: 0.3218 - val_acc: 0.9097\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.1018 - acc: 0.9546 - val_loss: 0.3760 - val_acc: 0.9125\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.0994 - acc: 0.9572 - val_loss: 0.5157 - val_acc: 0.8975\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.1119 - acc: 0.9532 - val_loss: 0.3961 - val_acc: 0.9026\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.1074 - acc: 0.9528 - val_loss: 0.4608 - val_acc: 0.9125\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.0966 - acc: 0.9572 - val_loss: 0.3860 - val_acc: 0.9111\n",
      "---------------------------------------------------------------------------------------------\n",
      "Results for model with dropout: 0.25, multiple_layers: False\n",
      "[[470   1  25   0   0   0]\n",
      " [ 10 460   1   0   0   0]\n",
      " [  0  12 407   0   0   1]\n",
      " [  0  19   0 368  99   5]\n",
      " [  0   2   0  60 470   0]\n",
      " [  0  27   0   0   0 510]]\n",
      "2947/2947 [==============================] - 3s 850us/step\n",
      "Accuracy: 0.9110960298608755\n",
      "---------------------------------------------------------------------------------------------\n",
      "Running for dropout: 0.25, layers: True\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.6251 - acc: 0.7427 - val_loss: 0.5664 - val_acc: 0.8185\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.2083 - acc: 0.9193 - val_loss: 0.5114 - val_acc: 0.8531\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1484 - acc: 0.9404 - val_loss: 0.4399 - val_acc: 0.8687\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1307 - acc: 0.9457 - val_loss: 0.4554 - val_acc: 0.8772\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1304 - acc: 0.9448 - val_loss: 0.3970 - val_acc: 0.8941\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1310 - acc: 0.9453 - val_loss: 0.3860 - val_acc: 0.9036\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1150 - acc: 0.9518 - val_loss: 0.4282 - val_acc: 0.8948\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1226 - acc: 0.9480 - val_loss: 0.5166 - val_acc: 0.8490\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1160 - acc: 0.9495 - val_loss: 0.3482 - val_acc: 0.9067\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1212 - acc: 0.9494 - val_loss: 0.3232 - val_acc: 0.9108\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1155 - acc: 0.9504 - val_loss: 0.3108 - val_acc: 0.9179\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1171 - acc: 0.9479 - val_loss: 0.3281 - val_acc: 0.9114\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1140 - acc: 0.9494 - val_loss: 0.3387 - val_acc: 0.9270\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1121 - acc: 0.9479 - val_loss: 0.2967 - val_acc: 0.9220\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1112 - acc: 0.9493 - val_loss: 0.2987 - val_acc: 0.9209\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1115 - acc: 0.9502 - val_loss: 0.3132 - val_acc: 0.9046\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1141 - acc: 0.9504 - val_loss: 0.3975 - val_acc: 0.8972\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1135 - acc: 0.9509 - val_loss: 0.3071 - val_acc: 0.9101\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1053 - acc: 0.9539 - val_loss: 0.3605 - val_acc: 0.8992\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1067 - acc: 0.9523 - val_loss: 0.2794 - val_acc: 0.9226\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1192 - acc: 0.9501 - val_loss: 0.3403 - val_acc: 0.9128\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1054 - acc: 0.9504 - val_loss: 0.3517 - val_acc: 0.8958\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1006 - acc: 0.9548 - val_loss: 0.3757 - val_acc: 0.9152\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1028 - acc: 0.9538 - val_loss: 0.4221 - val_acc: 0.9026\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1062 - acc: 0.9527 - val_loss: 0.4133 - val_acc: 0.9070\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.0968 - acc: 0.9580 - val_loss: 0.3185 - val_acc: 0.8982\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.0935 - acc: 0.9555 - val_loss: 0.3152 - val_acc: 0.9060\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.0936 - acc: 0.9574 - val_loss: 0.4383 - val_acc: 0.9074\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.0927 - acc: 0.9567 - val_loss: 0.3647 - val_acc: 0.9087\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.0893 - acc: 0.9572 - val_loss: 0.5014 - val_acc: 0.8918\n",
      "---------------------------------------------------------------------------------------------\n",
      "Results for model with dropout: 0.25, multiple_layers: True\n",
      "[[493   3   0   0   0   0]\n",
      " [  8 453   1   0   9   0]\n",
      " [ 35  23 362   0   0   0]\n",
      " [  0   4   0 385  98   4]\n",
      " [  1   1   0 105 425   0]\n",
      " [  0   0   0   0  27 510]]\n",
      "2947/2947 [==============================] - 4s 1ms/step\n",
      "Accuracy: 0.8917543264336614\n",
      "---------------------------------------------------------------------------------------------\n",
      "Running for dropout: 0.4, layers: False\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.5355 - acc: 0.7841 - val_loss: 0.4719 - val_acc: 0.8697\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1737 - acc: 0.9328 - val_loss: 0.3176 - val_acc: 0.8962\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1384 - acc: 0.9425 - val_loss: 0.3272 - val_acc: 0.8948\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1298 - acc: 0.9460 - val_loss: 0.3539 - val_acc: 0.9050\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1201 - acc: 0.9494 - val_loss: 0.3377 - val_acc: 0.9077\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1270 - acc: 0.9470 - val_loss: 0.3547 - val_acc: 0.9067\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1135 - acc: 0.9524 - val_loss: 0.3303 - val_acc: 0.9080\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1242 - acc: 0.9482 - val_loss: 0.3349 - val_acc: 0.9077\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1214 - acc: 0.9445 - val_loss: 0.3214 - val_acc: 0.9050\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1159 - acc: 0.9471 - val_loss: 0.3454 - val_acc: 0.9036\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1055 - acc: 0.9525 - val_loss: 0.3989 - val_acc: 0.9175\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1062 - acc: 0.9510 - val_loss: 0.4415 - val_acc: 0.9087\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1132 - acc: 0.9499 - val_loss: 0.3441 - val_acc: 0.9026\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1098 - acc: 0.9520 - val_loss: 0.3708 - val_acc: 0.9033\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1113 - acc: 0.9491 - val_loss: 0.3985 - val_acc: 0.9097\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1015 - acc: 0.9524 - val_loss: 0.4142 - val_acc: 0.9104\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0984 - acc: 0.9554 - val_loss: 0.4063 - val_acc: 0.9050\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.0945 - acc: 0.9546 - val_loss: 0.3950 - val_acc: 0.9097\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0970 - acc: 0.9565 - val_loss: 0.4758 - val_acc: 0.8938\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0917 - acc: 0.9592 - val_loss: 0.4812 - val_acc: 0.8924\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0914 - acc: 0.9576 - val_loss: 0.4585 - val_acc: 0.9070\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0883 - acc: 0.9597 - val_loss: 0.4291 - val_acc: 0.9169\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0880 - acc: 0.9584 - val_loss: 0.4370 - val_acc: 0.9023\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0891 - acc: 0.9589 - val_loss: 0.4401 - val_acc: 0.9030\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1045 - acc: 0.9580 - val_loss: 0.6000 - val_acc: 0.8867\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0934 - acc: 0.9615 - val_loss: 0.5342 - val_acc: 0.8999\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0814 - acc: 0.9623 - val_loss: 0.5649 - val_acc: 0.8867\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0800 - acc: 0.9623 - val_loss: 0.5218 - val_acc: 0.8843\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0806 - acc: 0.9623 - val_loss: 0.4794 - val_acc: 0.9026\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.0768 - acc: 0.9648 - val_loss: 0.4821 - val_acc: 0.8826\n",
      "---------------------------------------------------------------------------------------------\n",
      "Results for model with dropout: 0.4, multiple_layers: False\n",
      "[[475   9  12   0   0   0]\n",
      " [ 16 449   6   0   0   0]\n",
      " [  2   5 413   0   0   0]\n",
      " [  0  20   0 303 162   6]\n",
      " [  1   2   0  77 452   0]\n",
      " [  0  28   0   0   0 509]]\n",
      "2947/2947 [==============================] - 2s 826us/step\n",
      "Accuracy: 0.8825924669155073\n",
      "---------------------------------------------------------------------------------------------\n",
      "Running for dropout: 0.4, layers: True\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.6629 - acc: 0.7273 - val_loss: 0.4889 - val_acc: 0.8398\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1932 - acc: 0.9238 - val_loss: 0.3888 - val_acc: 0.8938\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1503 - acc: 0.9388 - val_loss: 0.3981 - val_acc: 0.8816\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1359 - acc: 0.9425 - val_loss: 0.4085 - val_acc: 0.8945\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.1355 - acc: 0.9426 - val_loss: 0.3362 - val_acc: 0.8975\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1343 - acc: 0.9434 - val_loss: 0.3168 - val_acc: 0.9053\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1323 - acc: 0.9459 - val_loss: 0.3045 - val_acc: 0.9050\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1195 - acc: 0.9480 - val_loss: 0.3694 - val_acc: 0.9063\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1244 - acc: 0.9455 - val_loss: 0.4085 - val_acc: 0.9009\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1185 - acc: 0.9470 - val_loss: 0.3848 - val_acc: 0.9074\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1172 - acc: 0.9495 - val_loss: 0.3317 - val_acc: 0.9148\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1301 - acc: 0.9475 - val_loss: 0.3784 - val_acc: 0.9097\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1224 - acc: 0.9474 - val_loss: 0.3467 - val_acc: 0.9169\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1150 - acc: 0.9487 - val_loss: 0.3422 - val_acc: 0.9125\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1160 - acc: 0.9499 - val_loss: 0.3764 - val_acc: 0.9006\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1124 - acc: 0.9489 - val_loss: 0.3615 - val_acc: 0.9152\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1103 - acc: 0.9498 - val_loss: 0.3660 - val_acc: 0.9175\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1177 - acc: 0.9457 - val_loss: 0.6127 - val_acc: 0.8534\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1215 - acc: 0.9471 - val_loss: 0.3251 - val_acc: 0.9050\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1268 - acc: 0.9494 - val_loss: 0.2771 - val_acc: 0.9070\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1105 - acc: 0.9494 - val_loss: 0.4971 - val_acc: 0.8945\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1095 - acc: 0.9529 - val_loss: 0.3134 - val_acc: 0.9118\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1076 - acc: 0.9517 - val_loss: 0.3199 - val_acc: 0.9094\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1234 - acc: 0.9474 - val_loss: 0.2751 - val_acc: 0.9155\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1088 - acc: 0.9523 - val_loss: 0.3268 - val_acc: 0.9172\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1088 - acc: 0.9532 - val_loss: 0.3137 - val_acc: 0.9087\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1047 - acc: 0.9531 - val_loss: 0.3247 - val_acc: 0.9253\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1058 - acc: 0.9521 - val_loss: 0.3643 - val_acc: 0.9074\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1016 - acc: 0.9551 - val_loss: 0.3583 - val_acc: 0.9199\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1066 - acc: 0.9540 - val_loss: 0.3501 - val_acc: 0.9175\n",
      "---------------------------------------------------------------------------------------------\n",
      "Results for model with dropout: 0.4, multiple_layers: True\n",
      "[[478   0  18   0   0   0]\n",
      " [ 11 437  23   0   0   0]\n",
      " [  1   0 419   0   0   0]\n",
      " [  0  19   0 378  88   6]\n",
      " [  0   1   0  75 456   0]\n",
      " [  0   1   0   0   0 536]]\n",
      "2947/2947 [==============================] - 4s 1ms/step\n",
      "Accuracy: 0.9175432643366135\n",
      "---------------------------------------------------------------------------------------------\n",
      "Running for dropout: 0.5, layers: False\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.5568 - acc: 0.7771 - val_loss: 0.5719 - val_acc: 0.8045\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1820 - acc: 0.9304 - val_loss: 0.3395 - val_acc: 0.8836\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1494 - acc: 0.9408 - val_loss: 0.3333 - val_acc: 0.8955\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1304 - acc: 0.9472 - val_loss: 0.3192 - val_acc: 0.9040\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1276 - acc: 0.9464 - val_loss: 0.2753 - val_acc: 0.9040\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1258 - acc: 0.9474 - val_loss: 0.3529 - val_acc: 0.9046\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1175 - acc: 0.9486 - val_loss: 0.3582 - val_acc: 0.8843\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1297 - acc: 0.9470 - val_loss: 0.2548 - val_acc: 0.9175\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1161 - acc: 0.9498 - val_loss: 0.2903 - val_acc: 0.9063\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1140 - acc: 0.9510 - val_loss: 0.2941 - val_acc: 0.9067\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1130 - acc: 0.9514 - val_loss: 0.3185 - val_acc: 0.9077\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1285 - acc: 0.9465 - val_loss: 0.4359 - val_acc: 0.8887\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1142 - acc: 0.9495 - val_loss: 0.3859 - val_acc: 0.9057\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1123 - acc: 0.9501 - val_loss: 0.3557 - val_acc: 0.9077\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1148 - acc: 0.9509 - val_loss: 0.3610 - val_acc: 0.9094\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1172 - acc: 0.9497 - val_loss: 0.2768 - val_acc: 0.9138\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1093 - acc: 0.9528 - val_loss: 0.3736 - val_acc: 0.9019\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1085 - acc: 0.9516 - val_loss: 0.3792 - val_acc: 0.9084\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1076 - acc: 0.9527 - val_loss: 0.3592 - val_acc: 0.9094\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1071 - acc: 0.9513 - val_loss: 0.3710 - val_acc: 0.9135\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1236 - acc: 0.9491 - val_loss: 0.3307 - val_acc: 0.9206\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1077 - acc: 0.9517 - val_loss: 0.3173 - val_acc: 0.9148\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1062 - acc: 0.9546 - val_loss: 0.3132 - val_acc: 0.9141\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1083 - acc: 0.9538 - val_loss: 0.3303 - val_acc: 0.9121\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1091 - acc: 0.9536 - val_loss: 0.3064 - val_acc: 0.9158\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1036 - acc: 0.9532 - val_loss: 0.3143 - val_acc: 0.9175\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1182 - acc: 0.9510 - val_loss: 0.3048 - val_acc: 0.9063\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1095 - acc: 0.9524 - val_loss: 0.3354 - val_acc: 0.9067\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1057 - acc: 0.9527 - val_loss: 0.4136 - val_acc: 0.9091\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1039 - acc: 0.9551 - val_loss: 0.4024 - val_acc: 0.9067\n",
      "---------------------------------------------------------------------------------------------\n",
      "Results for model with dropout: 0.5, multiple_layers: False\n",
      "[[460   1  35   0   0   0]\n",
      " [  3 449  19   0   0   0]\n",
      " [  8   3 409   0   0   0]\n",
      " [  0   2   1 347 132   9]\n",
      " [  0   1   0  61 470   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "2947/2947 [==============================] - 2s 847us/step\n",
      "Accuracy: 0.9066847641669494\n",
      "---------------------------------------------------------------------------------------------\n",
      "Running for dropout: 0.5, layers: True\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.6252 - acc: 0.7482 - val_loss: 0.5565 - val_acc: 0.8144\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2332 - acc: 0.9165 - val_loss: 0.4306 - val_acc: 0.8571\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1729 - acc: 0.9354 - val_loss: 0.3936 - val_acc: 0.8806\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1553 - acc: 0.9359 - val_loss: 0.3338 - val_acc: 0.9019\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1433 - acc: 0.9419 - val_loss: 0.2968 - val_acc: 0.9097\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1319 - acc: 0.9452 - val_loss: 0.3307 - val_acc: 0.9070\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1379 - acc: 0.9431 - val_loss: 0.3594 - val_acc: 0.9026\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1253 - acc: 0.9456 - val_loss: 0.3183 - val_acc: 0.9046\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1280 - acc: 0.9474 - val_loss: 0.3441 - val_acc: 0.9097\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1211 - acc: 0.9506 - val_loss: 0.3250 - val_acc: 0.9114\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1208 - acc: 0.9491 - val_loss: 0.3236 - val_acc: 0.9080\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1237 - acc: 0.9493 - val_loss: 0.3086 - val_acc: 0.9128\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1150 - acc: 0.9499 - val_loss: 0.3366 - val_acc: 0.9125\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1320 - acc: 0.9427 - val_loss: 0.3503 - val_acc: 0.9074\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1204 - acc: 0.9476 - val_loss: 0.3614 - val_acc: 0.9138\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1198 - acc: 0.9489 - val_loss: 0.3388 - val_acc: 0.9087\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1143 - acc: 0.9501 - val_loss: 0.3361 - val_acc: 0.9046\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1150 - acc: 0.9505 - val_loss: 0.3803 - val_acc: 0.9158\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1129 - acc: 0.9516 - val_loss: 0.3496 - val_acc: 0.9145\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1212 - acc: 0.9510 - val_loss: 0.3951 - val_acc: 0.9080\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1164 - acc: 0.9504 - val_loss: 0.3607 - val_acc: 0.9094\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1139 - acc: 0.9505 - val_loss: 0.3430 - val_acc: 0.9141\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1139 - acc: 0.9535 - val_loss: 0.3831 - val_acc: 0.9060\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1124 - acc: 0.9506 - val_loss: 0.3859 - val_acc: 0.9057\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1114 - acc: 0.9504 - val_loss: 0.3874 - val_acc: 0.9131\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1118 - acc: 0.9504 - val_loss: 0.4026 - val_acc: 0.9104\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1163 - acc: 0.9504 - val_loss: 0.3854 - val_acc: 0.9148\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1100 - acc: 0.9532 - val_loss: 0.4702 - val_acc: 0.9040\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1090 - acc: 0.9517 - val_loss: 0.4379 - val_acc: 0.9111\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1197 - acc: 0.9508 - val_loss: 0.3833 - val_acc: 0.9162\n",
      "---------------------------------------------------------------------------------------------\n",
      "Results for model with dropout: 0.5, multiple_layers: True\n",
      "[[468   5  21   1   1   0]\n",
      " [  0 446  25   0   0   0]\n",
      " [  1   2 417   0   0   0]\n",
      " [  0   5   0 342 142   2]\n",
      " [  0   0   0  42 490   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "2947/2947 [==============================] - 4s 1ms/step\n",
      "Accuracy: 0.9161859518154055\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dropouts = [0.25, 0.40, 0.50]\n",
    "multiple_layers = [False, True]\n",
    "\n",
    "combinations = [(dropout, layers) for dropout in dropouts for layers in multiple_layers]\n",
    "\n",
    "for dropout, layers in combinations:\n",
    "    fit_model(dropout, layers, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Multiple LSTM Layers</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.926026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.911096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>0.891754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>0.882592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>0.917543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.906685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>0.916186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dropout Multiple LSTM Layers  Accuracy\n",
       "0     0.25                False  0.926026\n",
       "1     0.25                False  0.911096\n",
       "2     0.25                 True  0.891754\n",
       "3     0.40                False  0.882592\n",
       "4     0.40                 True  0.917543\n",
       "5     0.50                False  0.906685\n",
       "6     0.50                 True  0.916186"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
